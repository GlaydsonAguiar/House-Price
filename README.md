# ğŸ“˜ Projeto â€“ PrevisÃ£o com RegressÃ£o Linear

## ğŸ§  Objetivo
Desenvolver um modelo de **regressÃ£o linear** usando o scikit-learn para prever um valor-alvo com base em variÃ¡veis numÃ©ricas do dataset `train.csv`. O foco foi aplicar conceitos de **machine learning supervisionado** com validaÃ§Ã£o e avaliaÃ§Ã£o de desempenho.

---

## ğŸ“ Dataset
- Arquivo: `train.csv`
- ContÃ©m colunas numÃ©ricas e categÃ³ricas (ex: `MSSubClass`, `LotArea`, etc.).
- Usado para fins de aprendizado e validaÃ§Ã£o de modelo preditivo.

---

## ğŸ”§ Tecnologias e Bibliotecas
- **Python**
- **Pandas** â€“ ManipulaÃ§Ã£o e limpeza dos dados
- **NumPy** â€“ OperaÃ§Ãµes numÃ©ricas
- **Matplotlib** â€“ VisualizaÃ§Ã£o de dados
- **Scikit-learn** â€“ Treinamento, validaÃ§Ã£o e mÃ©trica do modelo de regressÃ£o

---

## ğŸ“Œ Etapas do Projeto
1. ğŸ“¥ **Leitura do Dataset**  
   - `pd.read_csv("train.csv")`

2. ğŸ§¹ **ExploraÃ§Ã£o e Limpeza de Dados**  
   - VerificaÃ§Ã£o de colunas, tipos e valores ausentes.
   - SeleÃ§Ã£o de variÃ¡veis relevantes.

3. ğŸ”€ **SeparaÃ§Ã£o em Treino e Teste**  
   - Usando `train_test_split` (80% treino / 20% teste).

4. ğŸ“ˆ **Treinamento do Modelo de RegressÃ£o Linear**  
   - `LinearRegression()` do scikit-learn.

5. ğŸ§ª **AvaliaÃ§Ã£o do Modelo**  
   - MÃ©trica usada: **Erro MÃ©dio Absoluto (MAE)**.

6. ğŸ“‰ **VisualizaÃ§Ã£o de Resultados**  
   - GrÃ¡fico de dispersÃ£o real vs. previsto.

---

## ğŸ“Š Exemplo de CÃ³digo
```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

# SeparaÃ§Ã£o em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Modelo
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# PrevisÃµes e avaliaÃ§Ã£o
y_pred = modelo.predict(X_test)
erro = mean_absolute_error(y_test, y_pred)
```

---

## ğŸ“ˆ Resultados
- O modelo obteve um **MAE** de aproximadamente `25` .
- A visualizaÃ§Ã£o mostra que a regressÃ£o teve desempenho razoÃ¡vel, mas com margem de erro em casos extremos.

---

## ğŸš€ PossÃ­veis Melhorias
- Normalizar as variÃ¡veis de entrada
- Testar outros algoritmos como Ridge, Lasso, RandomForest
- Ajustar hiperparÃ¢metros com GridSearchCV
- Tratar variÃ¡veis categÃ³ricas

---


